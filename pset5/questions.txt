0.  As far as the Oxford English Dictionary, it's an artificial word that supposedly means a lung disease acquired by inhaling very fine ash and sand dust.
1.  It returns the resource usage statistics for whatever process called it, which is the sum of resources used by all of the threads in the process.
2.  At least 16.
3.  One reason is that passing the pointers is faster and less resource intensive.
4.  Main() begins reading characters one at a time.  Once it encounters a designated illegal character or string, it spell checks the word so far as it has discovered it at this point.  Afterwards, it skips to the next word and begins reading that.  This process repeats until the end of the file is reached.
5.  fgetc is built to a better standard for this operation by default - not only does it scan the next character (and cast it as an int), if it finds that fp points to EOF, it will return EOF, and if something goes wrong, it will return an error.  It's not as easy to abuse or make mistakes with (in my opinion) and doesn't require all of the tweaking that fscanf requires to achieve somewhat comparable results.  Therefore it is faster to type, more efficient, and all around safer (again, in my opinion).  I also believe fgetc does a better job of handling things like blank spaces and escape sequences like new lines.  Also, we'd have to find some way to guarantee that the strings were formatted properly and try to minimize errors... fgetc is just superior for our needs in many ways.
6.  We don't want to change the data located at the pointers for this exercise, so declaring a const means we'll get an error if we somehow manage to change the data - which will keep us from shooting ourselves in the foot.
7.  Created bundles of indexes stored in nodes within a hash table!  Wooooords are inside my nodes?  I'm sleepy, I might have totally missed something in this question.  Sorry if I did!
8.  About .09 seconds I think!
9.  Implemented a more appropriate "SIZE" declaration, then refined it to make it smaller while still having some wiggle room.  Cut down on amount of code, optimized a few secontions to move faster, and switched from using a trie to a hash because I was seemingly making some blunders with the trie.  Eventually I just blew it all away and started over again, and felt that I got the hash table moving really quickly once I optimized load times.  Want it faster, but need sleep!
10. Yes.  I keep feeling like the load could be even faster, and I could possibly find a way to reduce check to .00 secs like the staff implementation, and maybe make unload time an absolute .00.  I found that when I hit .00 on unload that I was making a lot of collisions, though.  After optimizing it for no memory leaks with Valgrind, this was the fastest way I could figure out to make it.  I know I could check faster if I increased load times, but that doesn't optimize it for our test scenario, just for a permanent use scenario.  I think if I could devote a little extra time I could do those things, though!
